# Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Load dataset (you can replace with actual path or URL)
df = pd.read_csv("house_data.csv")  # Replace with your dataset name

# Drop unnecessary columns
df = df.drop(['Id'], axis=1)

# Handle missing values (simple approach)
df.fillna(df.median(numeric_only=True), inplace=True)
df.fillna("None", inplace=True)

# Encode categorical variables
categorical_cols = df.select_dtypes(include='object').columns
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])

# Create new features (feature engineering)
df['TotalBathrooms'] = df['FullBath'] + 0.5 * df['HalfBath']
df['HouseAge'] = df['YrSold'] - df['YearBuilt']
df['TotalArea'] = df['GrLivArea'] + df['TotalBsmtSF']

# Select features and target
X = df.drop(['SalePrice'], axis=1)
y = df['SalePrice']

# Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluate
rmse = mean_squared_error(y_test, y_pred, squared=False)
r2 = r2_score(y_test, y_pred)

print("Model Evaluation:")
print(f"RMSE: {rmse:.2f}")
print(f"RÂ² Score: {r2:.2f}")

# Plot: Actual vs Predicted
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')
plt.xlabel("Actual Sale Price")
plt.ylabel("Predicted Sale Price")
plt.title("Actual vs Predicted House Prices")
plt.show()

# Plot: Feature Importance
feature_importance = model.feature_importances_
features = X.columns
fi_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})
fi_df = fi_df.sort_values(by='Importance', ascending=False).head(10)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=fi_df)
plt.title("Top 10 Important Features")
plt.show()
